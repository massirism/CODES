{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "nlp_constructing_text_generation_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/massirism/Codes/blob/main/nlp_constructing_text_generation_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "punL79CN7Ox6"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "_ckMIh7O7s6D"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph5eir3Pf-3z"
      },
      "source": [
        "# Constructing a Text Generation Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Uhzt6vVIB2"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c03_nlp_constructing_text_generation_model.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c03_nlp_constructing_text_generation_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GbGfr_oLCat"
      },
      "source": [
        "Using most of the techniques you've already learned, it's now possible to generate new text by predicting the next word that follows a given seed word. To practice this method, we'll use the [Kaggle Song Lyrics Dataset](https://www.kaggle.com/mousehead/songlyrics)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aHK2CYygXom"
      },
      "source": [
        "## Import TensorFlow and related functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LmLTREBf5ng"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Other imports for processing data\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmLTO_dpgge9"
      },
      "source": [
        "## Get the Dataset\n",
        "\n",
        "As noted above, we'll utilize the [Song Lyrics dataset](https://www.kaggle.com/mousehead/songlyrics) on Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bf5FVHfganK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8624bd2-6221-428d-afcd-2b65351b6ae6"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
        "    -O /tmp/songdata.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-18 00:40:10--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.142.113, 74.125.142.139, 74.125.142.138, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.142.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/letse6n6sqp080srrp9nvgnhfkf0mgg4/1610930400000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-01-18 00:40:14--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/letse6n6sqp080srrp9nvgnhfkf0mgg4/1610930400000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 74.125.20.132, 2607:f8b0:400e:c07::84\n",
            "Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|74.125.20.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/csv]\n",
            "Saving to: ‘/tmp/songdata.csv’\n",
            "\n",
            "/tmp/songdata.csv       [    <=>             ]  69.08M  59.6MB/s    in 1.2s    \n",
            "\n",
            "2021-01-18 00:40:15 (59.6 MB/s) - ‘/tmp/songdata.csv’ saved [72436445]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu1BTzMIS1oy"
      },
      "source": [
        "## **First 10 Songs**\n",
        "\n",
        "Let's first look at just 10 songs from the dataset, and see how things perform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmb9rGaAUDO-"
      },
      "source": [
        "### Preprocessing\n",
        "\n",
        "Let's perform some basic preprocessing to get rid of punctuation and make everything lowercase. We'll then split the lyrics up by line and tokenize the lyrics.\n",
        "\n",
        "Vamos a realizar un preprocesamiento básico para eliminar la puntuación y hacer todo en minúsculas. Luego dividiremos las letras por líneas y haremos una ficha con las letras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AVAvyF_Vuh5"
      },
      "source": [
        "\n",
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "  \n",
        "#Se realiza un preprocesamiento básico para eliminar la puntuación y hacer todo en minúsculas. \n",
        "#Dividiremos las letras por líneas y haremos una ficha con las letras.\n",
        "def create_lyrics_corpus(dataset, field):\n",
        "  # Remove all other punctuation\n",
        "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
        "  # Make it lowercase\n",
        "  dataset[field] = dataset[field].str.lower()\n",
        "  # Make it one long string to split by line\n",
        "  lyrics = dataset[field].str.cat()\n",
        "  corpus = lyrics.split('\\n')\n",
        "  # Remove any trailing whitespace\n",
        "  for l in range(len(corpus)):\n",
        "    corpus[l] = corpus[l].rstrip()\n",
        "  # Remove any empty lines\n",
        "  corpus = [l for l in corpus if l != '']\n",
        "\n",
        "  return corpus"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apcEXp7WhVBs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4baea0b4-ecad-4482-e7e8-bdc89d91657f"
      },
      "source": [
        "# Read the dataset from csv - just first 10 songs for now\n",
        "dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:50]\n",
        "# Create the corpus using the 'text' column containing lyrics\n",
        "corpus = create_lyrics_corpus(dataset, 'text')\n",
        "# Tokenize the corpus\n",
        "tokenizer = tokenize_corpus(corpus)\n",
        "\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'i': 1, 'the': 2, 'you': 3, 'a': 4, 'and': 5, 'me': 6, 'to': 7, 'it': 8, 'of': 9, 'in': 10, 'my': 11, 'im': 12, 'that': 13, 'is': 14, 'your': 15, 'be': 16, 'so': 17, 'for': 18, 'we': 19, 'love': 20, 'on': 21, 'its': 22, 'youre': 23, 'all': 24, 'when': 25, 'do': 26, 'if': 27, 'can': 28, 'like': 29, 'know': 30, 'but': 31, 'make': 32, 'no': 33, 'were': 34, 'have': 35, 'gonna': 36, 'just': 37, 'see': 38, 'could': 39, 'this': 40, 'never': 41, 'take': 42, 'let': 43, 'now': 44, 'as': 45, 'will': 46, 'one': 47, 'through': 48, 'time': 49, 'with': 50, 'think': 51, 'hey': 52, 'girl': 53, 'am': 54, 'oh': 55, 'what': 56, 'was': 57, 'every': 58, 'honey': 59, 'way': 60, 'sing': 61, 'here': 62, 'dont': 63, 'are': 64, 'how': 65, 'feel': 66, 'our': 67, 'fernando': 68, 'ma': 69, 'new': 70, 'day': 71, 'nights': 72, 'theres': 73, 'well': 74, 'out': 75, 'there': 76, 'gimme': 77, 'at': 78, 'go': 79, 'song': 80, 'had': 81, 'then': 82, 'from': 83, 'only': 84, 'good': 85, 'not': 86, 'wasnt': 87, 'she': 88, 'yes': 89, 'more': 90, 'hear': 91, 'night': 92, 'they': 93, 'world': 94, 'still': 95, 'dance': 96, 'cant': 97, 'believe': 98, 'music': 99, 'life': 100, 'get': 101, 'happy': 102, 'always': 103, 'would': 104, 'everything': 105, 'man': 106, 'feeling': 107, 'cause': 108, 'down': 109, 'away': 110, 'ive': 111, 'too': 112, 'baby': 113, 'andante': 114, 'little': 115, 'boomaboomerang': 116, 'over': 117, 'again': 118, 'eyes': 119, 'an': 120, 'youll': 121, 'been': 122, 'before': 123, 'say': 124, 'thats': 125, 'look': 126, 'soul': 127, 'give': 128, 'helen': 129, 'marionette': 130, 'please': 131, 'ill': 132, 'dumb': 133, 'last': 134, 'alone': 135, 'where': 136, 'going': 137, 'fire': 138, 'true': 139, 'kisses': 140, 'bang': 141, 'while': 142, 'us': 143, 'leave': 144, 'bad': 145, 'que': 146, 'ever': 147, 'blue': 148, 'gotta': 149, 'stay': 150, 'come': 151, 'city': 152, 'knowing': 153, 'right': 154, 'old': 155, 'face': 156, 'shes': 157, 'play': 158, 'better': 159, 'together': 160, 'sweet': 161, 'friend': 162, 'he': 163, 'dream': 164, 'goes': 165, 'heart': 166, 'suppper': 167, 'something': 168, 'who': 169, 'about': 170, 'easy': 171, 'light': 172, 'even': 173, 'another': 174, 'burning': 175, 'him': 176, 'help': 177, 'wont': 178, 'high': 179, 'got': 180, 'after': 181, 'roll': 182, 'kind': 183, 'boy': 184, 'darling': 185, 'mean': 186, 'into': 187, 'some': 188, 'chiquitita': 189, 'try': 190, 'want': 191, 'does': 192, 'find': 193, 'tonight': 194, 'year': 195, 'rockn': 196, 'fill': 197, 'hole': 198, 'trooppper': 199, 'hand': 200, 'saw': 201, 'own': 202, 'sad': 203, 'cry': 204, 'dancing': 205, 'did': 206, 'hes': 207, 'chance': 208, 'wonder': 209, 'nothing': 210, 'her': 211, 'makes': 212, 'need': 213, 'youve': 214, 'by': 215, 'once': 216, 'sorry': 217, 'wrong': 218, 'seems': 219, 'id': 220, 'thing': 221, 'shadows': 222, 'somewhere': 223, 'mother': 224, 'midnight': 225, 'people': 226, 'head': 227, 'things': 228, 'strong': 229, 'ground': 230, 'show': 231, 'theyre': 232, 'cassandra': 233, 'caught': 234, 'dreams': 235, 'tell': 236, 'sky': 237, 'crazy': 238, 'his': 239, 'long': 240, 'looking': 241, 'place': 242, 'dreamworld': 243, 'coming': 244, 'y': 245, 'givin': 246, 'days': 247, 'ours': 248, 'making': 249, 'up': 250, 'break': 251, 'thought': 252, 'learn': 253, 'smile': 254, 'return': 255, 'leaving': 256, 'fight': 257, 'sleep': 258, 'gone': 259, 'sun': 260, 'shining': 261, 'them': 262, 'youd': 263, 'cryin': 264, 'forget': 265, 'doesnt': 266, 'breaking': 267, 'funny': 268, 'hold': 269, 'angel': 270, 'diddle': 271, 'has': 272, 'die': 273, 'la': 274, 'lo': 275, 'waiting': 276, 'round': 277, 'darkness': 278, 'throw': 279, 'ahhah': 280, 'without': 281, 'talk': 282, 'near': 283, 'end': 284, 'somebody': 285, 'kiss': 286, 'free': 287, 'street': 288, 'playing': 289, 'listen': 290, 'didnt': 291, 'really': 292, 'hour': 293, 'morning': 294, 'back': 295, 'may': 296, 'brother': 297, 'goodbye': 298, 'having': 299, 'queen': 300, 'smiling': 301, 'maybe': 302, 'fun': 303, 'agnetha': 304, 'living': 305, 'sounds': 306, 'fiddle': 307, 'mind': 308, 'friends': 309, 'air': 310, 'si': 311, 'tuviera': 312, 'volverlo': 313, 'hacer': 314, 'haria': 315, 'ya': 316, 'twinkle': 317, 'room': 318, 'might': 319, 'heels': 320, 'cries': 321, 'returning': 322, 'super': 323, 'trooper': 324, 'mine': 325, 'walk': 326, 'touch': 327, 'slow': 328, 'why': 329, 'found': 330, 'meant': 331, 'much': 332, 'around': 333, 'care': 334, 'myself': 335, 'past': 336, 'wanted': 337, 'words': 338, 'future': 339, 'hard': 340, 'thinking': 341, 'blind': 342, 'lord': 343, 'turn': 344, 'yet': 345, 'young': 346, 'voice': 347, 'feelings': 348, 'within': 349, 'wed': 350, 'needs': 351, 'helping': 352, 'star': 353, 'lose': 354, 'bright': 355, 'en': 356, 'passing': 357, 'than': 358, 'honolulu': 359, 'hawaii': 360, 'lay': 361, 'hell': 362, 'treat': 363, 'stream': 364, 'yeah': 365, 'rhythm': 366, 'angels': 367, 'everybodys': 368, 'fine': 369, 'notion': 370, 'use': 371, 'tired': 372, 'though': 373, 'their': 374, 'crying': 375, 'must': 376, 'knew': 377, 'sure': 378, 'rain': 379, 'above': 380, 'couldnt': 381, 'closed': 382, 'realized': 383, 'lies': 384, 'meet': 385, 'nice': 386, 'remember': 387, 'same': 388, 'lights': 389, 'disillusion': 390, 'disillusions': 391, 'crowd': 392, 'movie': 393, 'meets': 394, 'whirl': 395, 'somehow': 396, 'speak': 397, 'eagle': 398, 'higher': 399, 'made': 400, 'comes': 401, 'gloom': 402, 'half': 403, 'guess': 404, 'someone': 405, 'sometimes': 406, 'live': 407, 'lonely': 408, 'very': 409, 'middle': 410, 'ending': 411, 'noise': 412, 'constant': 413, 'steady': 414, 'beats': 415, 'streets': 416, 'cross': 417, 'mirror': 418, 'kong': 419, 'point': 420, 'devotions': 421, 'landslide': 422, 'emotions': 423, 'leaves': 424, 'breeze': 425, 'such': 426, 'taking': 427, 'god': 428, 'yourself': 429, 'tender': 430, 'sender': 431, 'tune': 432, 'humdehumhum': 433, 'anywhere': 434, 'none': 435, 'darkest': 436, 'nobody': 437, 'late': 438, 'almost': 439, 'cool': 440, 'pain': 441, 'whats': 442, 'deny': 443, 'came': 444, 'other': 445, 'smiled': 446, 'seeing': 447, 'sitting': 448, 'lets': 449, 'knows': 450, 'flying': 451, 'king': 452, 'anyone': 453, 'left': 454, 'stars': 455, 'frida': 456, 'reality': 457, 'hopes': 458, 'wooh': 459, 'first': 460, 'or': 461, 'empty': 462, 'known': 463, 'atras': 464, 'por': 465, 'de': 466, 'each': 467, 'window': 468, 'twilight': 469, 'embers': 470, 'close': 471, 'autumn': 472, 'noone': 473, 'chase': 474, 'different': 475, 'done': 476, 'tight': 477, 'keeps': 478, 'depend': 479, 'woman': 480, 'leading': 481, 'pushing': 482, 'today': 483, 'children': 484, 'miss': 485, 'wide': 486, 'skyline': 487, 'energy': 488, 'laugh': 489, 'familiar': 490, 'frightening': 491, 'scares': 492, 'coward': 493, 'lifetime': 494, 'alright': 495, 'beams': 496, 'number': 497, 'ahhaa': 498, 'special': 499, 'park': 500, 'walking': 501, 'grow': 502, 'sound': 503, 'tread': 504, 'lightly': 505, 'saying': 506, 'used': 507, 'dumbedumdum': 508, 'bedumbedumdum': 509, 'fool': 510, 'warm': 511, 'surrender': 512, 'dumbbedumbdumb': 513, 'bedumbbedumbdumb': 514, 'moving': 515, 'dead': 516, 'lost': 517, 'start': 518, 'misunderstood': 519, 'dawning': 520, 'warning': 521, 'power': 522, 'weave': 523, 'until': 524, 'final': 525, 'ship': 526, 'grieving': 527, 'casting': 528, 'tomorrow': 529, 'quiet': 530, 'truth': 531, 'best': 532, 'walls': 533, 'emptiness': 534, 'feet': 535, 'men': 536, 'lot': 537, 'cold': 538, 'sittin': 539, 'memories': 540, 'jive': 541, 'watch': 542, 'scene': 543, 'diggin': 544, 'beat': 545, 'matter': 546, 'wishing': 547, 'chat': 548, 'flirt': 549, 'trust': 550, 'escape': 551, 'fuss': 552, 'far': 553, 'fly': 554, 'travel': 555, 'side': 556, 'should': 557, 'drums': 558, 'softly': 559, 'grey': 560, 'tu': 561, 'con': 562, 'algo': 563, 'habia': 564, 'alrededor': 565, 'quiza': 566, 'claridad': 567, 'brillaba': 568, 'nosotros': 569, 'dos': 570, 'proteccion': 571, 'pensabamos': 572, 'jamas': 573, 'perder': 574, 'ni': 575, 'echar': 576, 'beautiful': 577, 'goodnight': 578, 'finally': 579, 'outside': 580, 'mmm': 581, 'awake': 582, 'become': 583, 'images': 584, 'soon': 585, 'winds': 586, 'prays': 587, 'open': 588, 'second': 589, 'vision': 590, 'neighbor': 591, 'lives': 592, 'others': 593, 'heard': 594, 'trace': 595, 'hesitation': 596, 'unknown': 597, 'jungles': 598, 'taste': 599, 'rushing': 600, 'setting': 601, 'pace': 602, 'running': 603, 'gauntlet': 604, 'lace': 605, 'extreme': 606, 'til': 607, 'between': 608, 'forever': 609, 'worse': 610, 'conceal': 611, 'thrill': 612, 'any': 613, 'whispered': 614, 'strange': 615, 'arms': 616, 'voices': 617, 'language': 618, 'famous': 619, 'hotels': 620, 'cocktail': 621, 'bars': 622, 'smells': 623, 'turmoil': 624, 'cars': 625, 'breathing': 626, 'tear': 627, 'sigh': 628, 'speaking': 629, 'these': 630, 'fall': 631, 'belong': 632, 'pull': 633, 'string': 634, 'pet': 635, 'pirouette': 636, 'silly': 637, 'clown': 638, 'dreadful': 639, 'mighty': 640, 'killer': 641, 'big': 642, 'black': 643, 'gorilla': 644, 'chorus': 645, 'monkey': 646, 'riding': 647, 'means': 648, 'sees': 649, 'hours': 650, 'gently': 651, 'summer': 652, 'evening': 653, 'slowly': 654, 'thousand': 655, 'lousy': 656, 'packing': 657, 'keeping': 658, 'intention': 659, 'growing': 660, 'dimension': 661, 'thank': 662, 'mistake': 663, 'question': 664, 'advice': 665, 'selfish': 666, 'tool': 667, 'showing': 668, 'boomerang': 669, 'throwing': 670, 'giving': 671, 'mad': 672, 'under': 673, 'sick': 674, 'aint': 675, 'walkin': 676, 'door': 677, 'bridges': 678, 'eye': 679, 'being': 680, 'alive': 681, 'shame': 682, 'behind': 683, 'laughter': 684, 'reason': 685, 'wait': 686, 'sunrise': 687, 'stood': 688, 'filled': 689, 'hope': 690, 'hate': 691, 'heartaches': 692, 'scars': 693, 'loves': 694, 'house': 695, 'guy': 696, 'part': 697, 'move': 698, 'said': 699, 'waitin': 700, 'chills': 701, 'bone': 702, 'tonights': 703, 'borrow': 704, 'memory': 705, 'weve': 706, 'trying': 707, 'blame': 708, 'met': 709, 'fade': 710, 'low': 711, 'getting': 712, 'anybody': 713, 'rock': 714, 'mood': 715, 'seventeen': 716, 'tambourine': 717, 'changing': 718, 'laughing': 719, 'doing': 720, 'wild': 721, 'child': 722, 'seem': 723, 'style': 724, 'pretend': 725, 'reach': 726, 'work': 727, 'violin': 728, 'wish': 729, 'hearing': 730, 'theyve': 731, 'seen': 732, 'land': 733, 'spread': 734, 'wings': 735, 'bird': 736, 'rides': 737, 'mountains': 738, 'forests': 739, 'seas': 740, 'wing': 741, 'questions': 742, 'dreaming': 743, 'guiding': 744, 'dark': 745, 'afar': 746, 'prepared': 747, 'liberty': 748, 'regret': 749, 'years': 750, 'freedom': 751, 'x2': 752, 'escuchar': 753, 'una': 754, 'yo': 755, 'se': 756, 'el': 757, 'hoy': 758, 'depressed': 759, 'working': 760, 'bumble': 761, 'bee': 762, 'lie': 763, 'trees': 764, 'rustling': 765, 'falls': 766, 'fireplace': 767, 'dying': 768, 'peaceful': 769, 'solitude': 770, 'subdued': 771, 'forgotten': 772, 'scenes': 773, 'present': 774, 'runs': 775, 'entwined': 776, 'games': 777, 'prolonged': 778, 'spend': 779, 'blowing': 780, 'fortune': 781, 'win': 782, 'sight': 783, 'call': 784, 'ask': 785, 'bring': 786, 'loving': 787, 'tears': 788, 'fell': 789, 'those': 790, 'plain': 791, 'plans': 792, 'gives': 793, 'imagine': 794, 'holding': 795, 'ten': 796, 'happened': 797, 'praying': 798, 'road': 799, 'comfort': 800, 'compassion': 801, 'begging': 802, 'everywhere': 803, 'chair': 804, 'lady': 805, 'says': 806, 'two': 807, 'hello': 808, 'river': 809, 'flow': 810, 'wind': 811, 'both': 812, 'misfortune': 813, 'worth': 814, 'hurt': 815, 'blues': 816, 'burden': 817, 'weighed': 818, 'shoes': 819, 'worst': 820, 'cursed': 821, 'loose': 822, 'songs': 823, 'nearly': 824, 'kill': 825, 'machine': 826, 'rather': 827, 'looks': 828, 'cloud': 829, 'revelation': 830, 'spreading': 831, 'irresistible': 832, 'creature': 833, 'size': 834, 'million': 835, 'blend': 836, 'single': 837, 'glamor': 838, 'crowded': 839, 'pay': 840, 'choice': 841, 'cope': 842, 'anything': 843, 'fairy': 844, 'tale': 845, 'fail': 846, 'beauty': 847, 'joke': 848, 'farce': 849, 'longer': 850, 'needed': 851, 'looked': 852, 'houses': 853, 'walked': 854, 'dear': 855, 'married': 856, 'homes': 857, 'wellplanned': 858, 'wise': 859, 'expecting': 860, 'surprises': 861, 'family': 862, 'dull': 863, 'town': 864, 'buses': 865, 'missed': 866, 'boys': 867, 'kissed': 868, 'keep': 869, 'doin': 870, 'courage': 871, 'fear': 872, 'starin': 873, 'wall': 874, 'write': 875, 'tellin': 876, 'outward': 877, 'bound': 878, 'pushed': 879, 'somethings': 880, 'delight': 881, 'excite': 882, 'pleading': 883, 'adore': 884, 'glad': 885, 'suddenly': 886, 'stage': 887, 'ends': 888, 'along': 889, 'share': 890, 'affairs': 891, 'compared': 892, 'memries': 893, 'theyll': 894, 'wonderful': 895, 'smiles': 896, 'lucky': 897, 'fellow': 898, 'holds': 899, 'squeezes': 900, 'talking': 901, 'plan': 902, 'fingers': 903, 'soft': 904, 'body': 905, 'velvet': 906, 'shimmer': 907, 'butterflies': 908, 'float': 909, 'put': 910, 'rotten': 911, 'tough': 912, 'stuff': 913, 'anymore': 914, 'enough': 915, 'standing': 916, 'creep': 917, 'felt': 918, 'cheap': 919, 'deep': 920, 'entitled': 921, 'beg': 922, 'forgive': 923, 'feels': 924, 'hoot': 925, 'holler': 926, 'heel': 927, 'holy': 928, 'christ': 929, 'deal': 930, 'tedious': 931, 'ways': 932, 'cutting': 933, 'tie': 934, 'wanna': 935, 'counting': 936, 'pride': 937, 'unright': 938, 'neighbours': 939, 'ride': 940, 'burying': 941, 'peace': 942, 'sucker': 943, 'singing': 944, 'shouting': 945, 'staying': 946, 'hiding': 947, 'hollow': 948, 'bed': 949, 'pity': 950, 'believed': 951, 'suffer': 952, 'sell': 953, 'secrets': 954, 'bargain': 955, 'smart': 956, 'aching': 957, 'hearts': 958, 'sailing': 959, 'father': 960, 'sister': 961, 'linger': 962, 'deeply': 963, 'shadow': 964, 'else': 965, 'fate': 966, 'bags': 967, 'thorough': 968, 'watched': 969, 'harbor': 970, 'sails': 971, 'slack': 972, 'deck': 973, 'tiny': 974, 'figure': 975, 'rigid': 976, 'restrained': 977, 'enchained': 978, 'sorrow': 979, 'shoulder': 980, 'rely': 981, 'broken': 982, 'feather': 983, 'patch': 984, 'tumbling': 985, 'blown': 986, 'candle': 987, 'handle': 988, 'went': 989, 'hardly': 990, 'closing': 991, 'front': 992, 'disapeared': 993, 'car': 994, 'stunned': 995, 'dreamed': 996, 'lifes': 997, 'pavement': 998, 'acted': 999, 'told': 1000, 'guys': 1001, 'stupid': 1002, 'took': 1003, 'couple': 1004, 'joe': 1005, 'nothings': 1006, 'nobodys': 1007, 'snowbird': 1008, 'friday': 1009, 'swing': 1010, 'musics': 1011, 'bit': 1012, 'teaser': 1013, 'em': 1014, 'circle': 1015, 'hoping': 1016, 'chasing': 1017, 'wondering': 1018, 'stop': 1019, 'loud': 1020, 'wound': 1021, 'heal': 1022, 'scar': 1023, 'shared': 1024, 'hot': 1025, 'teasing': 1026, 'chick': 1027, 'read': 1028, 'driving': 1029, 'ah': 1030, 'pretty': 1031, 'searching': 1032, 'cute': 1033, 'flash': 1034, 'hollywood': 1035, 'charming': 1036, 'groovy': 1037, 'expectations': 1038, 'fedup': 1039, 'acquisitions': 1040, 'white': 1041, 'practising': 1042, 'improve': 1043, 'everytime': 1044, 'exist': 1045, 'listened': 1046, 'fair': 1047, 'spell': 1048, 'stories': 1049, 'places': 1050, 'beyond': 1051, 'horizons': 1052, 'strangely': 1053, 'understand': 1054, 'limit': 1055, 'climb': 1056, 'real': 1057, 'ago': 1058, 'starry': 1059, 'firelight': 1060, 'humming': 1061, 'strumming': 1062, 'guitar': 1063, 'distant': 1064, 'bugle': 1065, 'calls': 1066, 'closer': 1067, 'minute': 1068, 'seemed': 1069, 'eternally': 1070, 'afraid': 1071, 'full': 1072, 'ashamed': 1073, 'roar': 1074, 'guns': 1075, 'cannons': 1076, 'since': 1077, 'many': 1078, 'havent': 1079, 'rifle': 1080, 'recall': 1081, 'frightful': 1082, 'crossed': 1083, 'rio': 1084, 'grande': 1085, 'proud': 1086, 'repeat': 1087, 'puedes': 1088, 'recuerda': 1089, 'tiempo': 1090, 'estrellas': 1091, 'noche': 1092, 'alla': 1093, 'lumbre': 1094, 'azul': 1095, 'tarareabas': 1096, 'cancion': 1097, 'ese': 1098, 'suave': 1099, 'guitarrear': 1100, 'podia': 1101, 'esos': 1102, 'tambores': 1103, 'un': 1104, 'sordo': 1105, 'redoblar': 1106, 'acercaban': 1107, 'mas': 1108, 'momento': 1109, 'pasaba': 1110, 'parecia': 1111, 'eternidad': 1112, 'senti': 1113, 'temor': 1114, 'vida': 1115, 'juventud': 1116, 'nadie': 1117, 'pensaba': 1118, 'morir': 1119, 'siento': 1120, 'verguenza': 1121, 'al': 1122, 'confesar': 1123, 'tuve': 1124, 'ganas': 1125, 'llorar': 1126, 'vejez': 1127, 'llego': 1128, 'ella': 1129, 'paz': 1130, 'logramos': 1131, 'disfrutar': 1132, 'durmio': 1133, 'tambor': 1134, 'paraciera': 1135, 'fue': 1136, 'ayer': 1137, 'vivimos': 1138, 'tus': 1139, 'ojos': 1140, 'veo': 1141, 'aun': 1142, 'aquel': 1143, 'orgullo': 1144, 'refleja': 1145, 'valor': 1146, 'repeata': 1147, 'next': 1148, 'bus': 1149, 'travelling': 1150, 'downtown': 1151, 'isnt': 1152, 'weather': 1153, 'sip': 1154, 'flower': 1155, 'lazy': 1156, 'lying': 1157, 'laid': 1158, 'railroad': 1159, 'bum': 1160, 'track': 1161, 'outdoors': 1162, 'grass': 1163, 'chew': 1164, 'straw': 1165, 'diamond': 1166, 'glittring': 1167, 'shine': 1168, 'bend': 1169, 'milky': 1170, 'raindrops': 1171, 'pane': 1172, 'stillness': 1173, 'silently': 1174, 'haze': 1175, 'drifts': 1176, 'dawn': 1177, 'curtins': 1178, 'trapped': 1179, 'daylight': 1180, 'backs': 1181, 'echoes': 1182, 'awaited': 1183, 'warms': 1184, 'twelve': 1185, 'watching': 1186, 'flat': 1187, 'rainbow': 1188, 't': 1189, 'v': 1190, 'gaze': 1191, 'gentleness': 1192, 'rubbing': 1193, 'off': 1194, 'loneliness': 1195, 'phone': 1196, 'patient': 1197, 'ooh': 1198, 'consolation': 1199, 'hmm': 1200, 'eternity': 1201, 'miracle': 1202, 'happen': 1203, 'lingered': 1204, 'falling': 1205, 'gets': 1206, 'bitter': 1207, 'autumns': 1208, 'chilly': 1209, 'skies': 1210, 'clouds': 1211, 'cannot': 1212, 'replaced': 1213, 'loved': 1214, 'early': 1215, 'drove': 1216, 'airport': 1217, 'alice': 1218, 'swimming': 1219, 'surfing': 1220, 'enjoying': 1221, 'vacation': 1222, 'send': 1223, 'card': 1224, 'greeting': 1225, 'exciting': 1226, 'few': 1227, 'plane': 1228, 'descend': 1229, 'beach': 1230, 'sand': 1231, 'champagne': 1232, 'fireworks': 1233, 'party': 1234, 'unlike': 1235, 'yesterday': 1236, 'nows': 1237, 'brave': 1238, 'arrives': 1239, 'thrives': 1240, 'ashes': 1241, 'thinks': 1242, 'okay': 1243, 'dragging': 1244, 'clay': 1245, 'astray': 1246, 'anyway': 1247, 'confetti': 1248, 'floor': 1249, 'decade': 1250, 'line': 1251, 'eightynine': 1252, 'benny': 1253, 'fighter': 1254, 'trouble': 1255, 'turned': 1256, 'likes': 1257, 'follow': 1258, 'trend': 1259, 'personal': 1260, 'tend': 1261, 'admire': 1262, 'courageous': 1263, 'constantly': 1264, 'speaks': 1265, 'pats': 1266, 'exert': 1267, 'hurry': 1268, 'whatever': 1269, 'strands': 1270, 'driftwood': 1271, 'destined': 1272, 'bustin': 1273, 'dam': 1274, 'sail': 1275, 'upon': 1276, 'ocean': 1277, 'shoreline': 1278, 'carried': 1279, 'trade': 1280, 'favours': 1281, 'spun': 1282, 'wheel': 1283, 'scored': 1284, 'romance': 1285, 'stayed': 1286, 'broke': 1287, 'banks': 1288, 'gold': 1289, 'taken': 1290, 'las': 1291, 'vegas': 1292, 'cent': 1293, 'heaven': 1294, 'blessed': 1295, 'glove': 1296, 'price': 1297, 'paid': 1298, 'daddy': 1299, 'beginning': 1300, 'hahahad': 1301, 'sam': 1302, 'chauffeur': 1303, 'annie': 1304, 'school': 1305, 'jerry': 1306, 'works': 1307, 'office': 1308, 'sue': 1309, 'pool': 1310, 'weekends': 1311, 'lookin': 1312, 'action': 1313, 'paint': 1314, 'colors': 1315, 'romantic': 1316, 'spit': 1317, 'telling': 1318, 'thrills': 1319, 'dizzy': 1320, 'stick': 1321, 'rid': 1322, 'least': 1323, 'doggone': 1324, 'beast': 1325, 'among': 1326, 'simple': 1327, 'type': 1328, 'surely': 1329, 'evil': 1330, 'begun': 1331, 'attraction': 1332, 'vibrant': 1333, 'electrified': 1334, 'welcome': 1335, 'chances': 1336, 'contribution': 1337, 'melting': 1338, 'pot': 1339, 'feed': 1340, 'hungry': 1341, 'worship': 1342, 'homage': 1343, 'shopping': 1344, 'neon': 1345, 'dazzled': 1346, 'magic': 1347, 'grabbing': 1348, 'pieces': 1349, 'fatted': 1350, 'calf': 1351, 'parks': 1352, 'squares': 1353, 'fantasy': 1354, 'destination': 1355, 'mile': 1356, 'poet': 1357, 'painted': 1358, 'straight': 1359, 'acquainted': 1360, 'restrains': 1361, 'carry': 1362, 'healing': 1363, 'blow': 1364, 'shallow': 1365, 'dry': 1366, 'alley': 1367, 'ancient': 1368, 'valley': 1369, 'urging': 1370, 'lover': 1371, 'defeat': 1372, 'grand': 1373, 'illusion': 1374, 'disturbance': 1375, 'intrusion': 1376, 'wistful': 1377, 'seduce': 1378, 'joy': 1379, 'moment': 1380, 'dies': 1381, 'reservation': 1382, 'explanation': 1383, 'hanging': 1384, 'bother': 1385, 'appointments': 1386, 'keepin': 1387, 'busy': 1388, 'thinkin': 1389, 'restless': 1390, 'temper': 1391, 'times': 1392, 'clearly': 1393, 'business': 1394, 'bills': 1395, 'everythings': 1396, 'refuge': 1397, 'space': 1398, 'doll': 1399, 'puppet': 1400, 'taught': 1401, 'complain': 1402, 'happening': 1403, 'control': 1404, 'insane': 1405, 'photograph': 1406, 'ok': 1407, 'refugee': 1408, 'manage': 1409, 'hit': 1410, 'ceiling': 1411, 'brought': 1412, 'possibly': 1413, 'release': 1414, 'able': 1415, 'ease': 1416, 'someday': 1417, 'agree': 1418, 'called': 1419, 'glasgow': 1420, 'eat': 1421, 'trooppperfeeling': 1422, 'facing': 1423, 'twenty': 1424, 'success': 1425, 'moments': 1426, 'trooppperlike': 1427, 'arrive': 1428, 'prove': 1429, 'supper': 1430, 'troopper': 1431, 'watchin': 1432, 'reading': 1433, 'touching': 1434, 'mistaking': 1435, 'destiny': 1436, 'tv': 1437, 'n': 1438, 'band': 1439, 'bet': 1440, 'shout': 1441, 'beating': 1442, 'tomtom': 1443, 'jungle': 1444, 'gorillas': 1445, 'everybody': 1446, 'kinda': 1447, 'funky': 1448, 'hang': 1449, 'waddle': 1450, 'chest': 1451, 'apart': 1452, 'lips': 1453, 'fingertips': 1454, 'bout': 1455, 'safe': 1456, 'scared': 1457, 'losing': 1458, 'nightmare': 1459, 'babe': 1460, 'carefree': 1461, 'silence': 1462, 'story': 1463, 'rooms': 1464}\n",
            "1465\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9x68iN_X6FK"
      },
      "source": [
        "### Create Sequences and Labels\n",
        "\n",
        "After preprocessing, we next need to create sequences and labels. Creating the sequences themselves is similar to before with `texts_to_sequences`, but also including the use of [N-Grams](https://towardsdatascience.com/introduction-to-language-models-n-gram-e323081503d9); creating the labels will now utilize those sequences as well as utilize one-hot encoding over all potential output words.\n",
        "\n",
        "\n",
        "Después del preprocesamiento, necesitamos crear secuencias y etiquetas. La creación de las secuencias en sí es similar a la anterior con textos_a_secuencias, pero también incluye el uso de N-Gramas; la creación de las etiquetas utilizará ahora esas secuencias, así como la codificación de un solo paso sobre todas las posibles palabras de salida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmlTsUqfikVO"
      },
      "source": [
        "sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tsequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences for equal input length \n",
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
        "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
        "# One-hot encode the labels\n",
        "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zsmu3aEId49i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07f3ea3a-0df4-4edb-c3b4-3e633cd902e9"
      },
      "source": [
        "# Check out how some of our data is being stored\n",
        "# The Tokenizer has just a single index per word\n",
        "print(tokenizer.word_index['know'])\n",
        "print(tokenizer.word_index['feeling'])\n",
        "# Input sequences will have multiple indexes\n",
        "print(input_sequences[5])\n",
        "print(input_sequences[6])\n",
        "# And the one hot labels will be as long as the full spread of tokenized words\n",
        "print(one_hot_labels[5])\n",
        "print(one_hot_labels[6])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "107\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0 126  78 211 156  22\n",
            "   4]\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0 126  78 211 156  22   4\n",
            " 895]\n",
            "[0. 0. 0. ... 0. 0. 0.]\n",
            "[0. 0. 0. ... 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1TAJMlmfO8r"
      },
      "source": [
        "### Train a Text Generation Model\n",
        "\n",
        "Building an RNN to train our text generation model will be very similar to the sentiment models you've built previously. The only real change necessary is to make sure to use Categorical instead of Binary Cross Entropy as the loss function - we could use Binary before since the sentiment was only 0 or 1, but now there are hundreds of categories.\n",
        "\n",
        "From there, we should also consider using *more* epochs than before, as text generation can take a little longer to converge than sentiment analysis, *and* we aren't working with all that much data yet. I'll set it at 200 epochs here since we're only use part of the dataset, and training will tail off quite a bit over that many epochs.\n",
        "\n",
        "\n",
        "La construcción de un RNN para entrenar nuestro modelo de generación de texto será muy similar a los modelos de sentimiento que has construido anteriormente. El único cambio real necesario es asegurarse de usar Categorial en lugar de la Entropía Cruzada Binaria como la función de pérdida - antes podíamos usar Binario ya que el sentimiento era sólo 0 o 1, pero ahora hay cientos de categorías.\n",
        "\n",
        "A partir de ahí, también deberíamos considerar el uso de más épocas que antes, ya que la generación de texto puede tardar un poco más en converger que el análisis del sentimiento, y todavía no estamos trabajando con tantos datos. Lo fijaré en 200 épocas aquí, ya que sólo usamos parte del conjunto de datos, y el entrenamiento se reducirá bastante en esas épocas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1YXuxIqfygN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0cefda9-a213-4135-c94f-487f2f019eef"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "#Creación del modelo, bidireccional para hacer la memoria LSTM!\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(input_sequences, one_hot_labels, epochs=500, verbose=1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "327/327 [==============================] - 11s 8ms/step - loss: 6.5575 - accuracy: 0.0369\n",
            "Epoch 2/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 5.7492 - accuracy: 0.0416\n",
            "Epoch 3/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 5.6630 - accuracy: 0.0401\n",
            "Epoch 4/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 5.5634 - accuracy: 0.0449\n",
            "Epoch 5/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 5.4683 - accuracy: 0.0487\n",
            "Epoch 6/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 5.3277 - accuracy: 0.0593\n",
            "Epoch 7/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 5.2046 - accuracy: 0.0658\n",
            "Epoch 8/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 5.0953 - accuracy: 0.0738\n",
            "Epoch 9/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 4.9626 - accuracy: 0.0736\n",
            "Epoch 10/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 4.8942 - accuracy: 0.0801\n",
            "Epoch 11/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 4.7941 - accuracy: 0.0894\n",
            "Epoch 12/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 4.6661 - accuracy: 0.0986\n",
            "Epoch 13/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 4.5753 - accuracy: 0.1052\n",
            "Epoch 14/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 4.4960 - accuracy: 0.1128\n",
            "Epoch 15/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 4.4328 - accuracy: 0.1375\n",
            "Epoch 16/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 4.3233 - accuracy: 0.1450\n",
            "Epoch 17/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 4.2535 - accuracy: 0.1520\n",
            "Epoch 18/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 4.1579 - accuracy: 0.1713\n",
            "Epoch 19/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 4.1018 - accuracy: 0.1854\n",
            "Epoch 20/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 4.0429 - accuracy: 0.1929\n",
            "Epoch 21/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 3.9384 - accuracy: 0.2063\n",
            "Epoch 22/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 3.8687 - accuracy: 0.2155\n",
            "Epoch 23/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 3.8299 - accuracy: 0.2234\n",
            "Epoch 24/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 3.7102 - accuracy: 0.2413\n",
            "Epoch 25/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 3.6889 - accuracy: 0.2529\n",
            "Epoch 26/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 3.5742 - accuracy: 0.2647\n",
            "Epoch 27/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 3.5492 - accuracy: 0.2629\n",
            "Epoch 28/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 3.4343 - accuracy: 0.2964\n",
            "Epoch 29/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 3.3900 - accuracy: 0.2983\n",
            "Epoch 30/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 3.3396 - accuracy: 0.3189\n",
            "Epoch 31/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 3.3169 - accuracy: 0.3112\n",
            "Epoch 32/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 3.1904 - accuracy: 0.3269\n",
            "Epoch 33/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 3.1799 - accuracy: 0.3332\n",
            "Epoch 34/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 3.1981 - accuracy: 0.3258\n",
            "Epoch 35/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 3.0875 - accuracy: 0.3445\n",
            "Epoch 36/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 3.0506 - accuracy: 0.3532\n",
            "Epoch 37/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 3.0268 - accuracy: 0.3550\n",
            "Epoch 38/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.9943 - accuracy: 0.3547\n",
            "Epoch 39/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.9652 - accuracy: 0.3670\n",
            "Epoch 40/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.8259 - accuracy: 0.3936\n",
            "Epoch 41/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.8085 - accuracy: 0.3842\n",
            "Epoch 42/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.7379 - accuracy: 0.4086\n",
            "Epoch 43/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.7400 - accuracy: 0.4016\n",
            "Epoch 44/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.7204 - accuracy: 0.4093\n",
            "Epoch 45/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.6230 - accuracy: 0.4324\n",
            "Epoch 46/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.6466 - accuracy: 0.4246\n",
            "Epoch 47/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.5862 - accuracy: 0.4379\n",
            "Epoch 48/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.5484 - accuracy: 0.4509\n",
            "Epoch 49/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.5212 - accuracy: 0.4526\n",
            "Epoch 50/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.5050 - accuracy: 0.4634\n",
            "Epoch 51/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.4663 - accuracy: 0.4660\n",
            "Epoch 52/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.4622 - accuracy: 0.4685\n",
            "Epoch 53/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.4202 - accuracy: 0.4729\n",
            "Epoch 54/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.4172 - accuracy: 0.4743\n",
            "Epoch 55/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.3547 - accuracy: 0.4874\n",
            "Epoch 56/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.3251 - accuracy: 0.4923\n",
            "Epoch 57/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.3299 - accuracy: 0.4972\n",
            "Epoch 58/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.2575 - accuracy: 0.5051\n",
            "Epoch 59/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.2055 - accuracy: 0.5138\n",
            "Epoch 60/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.1693 - accuracy: 0.5254\n",
            "Epoch 61/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.1956 - accuracy: 0.5209\n",
            "Epoch 62/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.1439 - accuracy: 0.5323\n",
            "Epoch 63/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.1301 - accuracy: 0.5318\n",
            "Epoch 64/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.1213 - accuracy: 0.5332\n",
            "Epoch 65/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.0927 - accuracy: 0.5376\n",
            "Epoch 66/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.0554 - accuracy: 0.5531\n",
            "Epoch 67/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.0689 - accuracy: 0.5458\n",
            "Epoch 68/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.0143 - accuracy: 0.5512\n",
            "Epoch 69/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.9932 - accuracy: 0.5606\n",
            "Epoch 70/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 2.0032 - accuracy: 0.5582\n",
            "Epoch 71/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.9387 - accuracy: 0.5685\n",
            "Epoch 72/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.9396 - accuracy: 0.5631\n",
            "Epoch 73/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.8953 - accuracy: 0.5754\n",
            "Epoch 74/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.8918 - accuracy: 0.5763\n",
            "Epoch 75/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.8873 - accuracy: 0.5763\n",
            "Epoch 76/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.8448 - accuracy: 0.5915\n",
            "Epoch 77/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.8475 - accuracy: 0.5816\n",
            "Epoch 78/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.8693 - accuracy: 0.5807\n",
            "Epoch 79/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.8558 - accuracy: 0.5757\n",
            "Epoch 80/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.8236 - accuracy: 0.5972\n",
            "Epoch 81/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.7884 - accuracy: 0.5952\n",
            "Epoch 82/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.7704 - accuracy: 0.5964\n",
            "Epoch 83/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.7093 - accuracy: 0.6166\n",
            "Epoch 84/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.7376 - accuracy: 0.6049\n",
            "Epoch 85/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.7411 - accuracy: 0.5999\n",
            "Epoch 86/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.7580 - accuracy: 0.5971\n",
            "Epoch 87/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.6608 - accuracy: 0.6188\n",
            "Epoch 88/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.6786 - accuracy: 0.6190\n",
            "Epoch 89/500\n",
            "327/327 [==============================] - 2s 8ms/step - loss: 1.6936 - accuracy: 0.6159\n",
            "Epoch 90/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.7243 - accuracy: 0.6032\n",
            "Epoch 91/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.6841 - accuracy: 0.6102\n",
            "Epoch 92/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.6454 - accuracy: 0.6234\n",
            "Epoch 93/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.6508 - accuracy: 0.6196\n",
            "Epoch 94/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.5992 - accuracy: 0.6318\n",
            "Epoch 95/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.8358 - accuracy: 0.5839\n",
            "Epoch 96/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.6907 - accuracy: 0.6163\n",
            "Epoch 97/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.6123 - accuracy: 0.6331\n",
            "Epoch 98/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.5893 - accuracy: 0.6325\n",
            "Epoch 99/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.5837 - accuracy: 0.6413\n",
            "Epoch 100/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.5541 - accuracy: 0.6431\n",
            "Epoch 101/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.5253 - accuracy: 0.6461\n",
            "Epoch 102/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.5101 - accuracy: 0.6518\n",
            "Epoch 103/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.5141 - accuracy: 0.6486\n",
            "Epoch 104/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.5004 - accuracy: 0.6556\n",
            "Epoch 105/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.4766 - accuracy: 0.6581\n",
            "Epoch 106/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.4391 - accuracy: 0.6662\n",
            "Epoch 107/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.4744 - accuracy: 0.6592\n",
            "Epoch 108/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.4635 - accuracy: 0.6637\n",
            "Epoch 109/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.4317 - accuracy: 0.6663\n",
            "Epoch 110/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.4668 - accuracy: 0.6589\n",
            "Epoch 111/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.4203 - accuracy: 0.6695\n",
            "Epoch 112/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.4033 - accuracy: 0.6715\n",
            "Epoch 113/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.3890 - accuracy: 0.6775\n",
            "Epoch 114/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.4030 - accuracy: 0.6738\n",
            "Epoch 115/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.3761 - accuracy: 0.6816\n",
            "Epoch 116/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.3721 - accuracy: 0.6798\n",
            "Epoch 117/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.3673 - accuracy: 0.6762\n",
            "Epoch 118/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.4009 - accuracy: 0.6620\n",
            "Epoch 119/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.4186 - accuracy: 0.6627\n",
            "Epoch 120/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.3710 - accuracy: 0.6752\n",
            "Epoch 121/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.4034 - accuracy: 0.6625\n",
            "Epoch 122/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.3454 - accuracy: 0.6760\n",
            "Epoch 123/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.3186 - accuracy: 0.6915\n",
            "Epoch 124/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.2938 - accuracy: 0.6929\n",
            "Epoch 125/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.3701 - accuracy: 0.6733\n",
            "Epoch 126/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.3039 - accuracy: 0.6901\n",
            "Epoch 127/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.2926 - accuracy: 0.6893\n",
            "Epoch 128/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.4826 - accuracy: 0.6465\n",
            "Epoch 129/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.3404 - accuracy: 0.6842\n",
            "Epoch 130/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.2975 - accuracy: 0.6889\n",
            "Epoch 131/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.3027 - accuracy: 0.6853\n",
            "Epoch 132/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.2716 - accuracy: 0.6962\n",
            "Epoch 133/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.2649 - accuracy: 0.6982\n",
            "Epoch 134/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.2022 - accuracy: 0.7177\n",
            "Epoch 135/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.2198 - accuracy: 0.7072\n",
            "Epoch 136/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.2442 - accuracy: 0.7022\n",
            "Epoch 137/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.2269 - accuracy: 0.7049\n",
            "Epoch 138/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.2238 - accuracy: 0.7083\n",
            "Epoch 139/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.2237 - accuracy: 0.7054\n",
            "Epoch 140/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.2192 - accuracy: 0.7076\n",
            "Epoch 141/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.2027 - accuracy: 0.7197\n",
            "Epoch 142/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.1812 - accuracy: 0.7182\n",
            "Epoch 143/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.1953 - accuracy: 0.7164\n",
            "Epoch 144/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.1545 - accuracy: 0.7192\n",
            "Epoch 145/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.1806 - accuracy: 0.7147\n",
            "Epoch 146/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.1447 - accuracy: 0.7254\n",
            "Epoch 147/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.1573 - accuracy: 0.7187\n",
            "Epoch 148/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.1774 - accuracy: 0.7198\n",
            "Epoch 149/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.1879 - accuracy: 0.7142\n",
            "Epoch 150/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.1259 - accuracy: 0.7304\n",
            "Epoch 151/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.1801 - accuracy: 0.7188\n",
            "Epoch 152/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.1045 - accuracy: 0.7289\n",
            "Epoch 153/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.0936 - accuracy: 0.7336\n",
            "Epoch 154/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.1809 - accuracy: 0.7177\n",
            "Epoch 155/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.1231 - accuracy: 0.7285\n",
            "Epoch 156/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.1363 - accuracy: 0.7245\n",
            "Epoch 157/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.1387 - accuracy: 0.7254\n",
            "Epoch 158/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.1107 - accuracy: 0.7278\n",
            "Epoch 159/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.0987 - accuracy: 0.7329\n",
            "Epoch 160/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.0912 - accuracy: 0.7388\n",
            "Epoch 161/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.0772 - accuracy: 0.7456\n",
            "Epoch 162/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.0531 - accuracy: 0.7404\n",
            "Epoch 163/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.0646 - accuracy: 0.7355\n",
            "Epoch 164/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.1080 - accuracy: 0.7378\n",
            "Epoch 165/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.0545 - accuracy: 0.7401\n",
            "Epoch 166/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.0364 - accuracy: 0.7489\n",
            "Epoch 167/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.0241 - accuracy: 0.7522\n",
            "Epoch 168/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.0416 - accuracy: 0.7469\n",
            "Epoch 169/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.0531 - accuracy: 0.7470\n",
            "Epoch 170/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.0955 - accuracy: 0.7311\n",
            "Epoch 171/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.0547 - accuracy: 0.7443\n",
            "Epoch 172/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.0276 - accuracy: 0.7472\n",
            "Epoch 173/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.0074 - accuracy: 0.7601\n",
            "Epoch 174/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.0071 - accuracy: 0.7568\n",
            "Epoch 175/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.0247 - accuracy: 0.7493\n",
            "Epoch 176/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.9884 - accuracy: 0.7583\n",
            "Epoch 177/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.0056 - accuracy: 0.7567\n",
            "Epoch 178/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.9991 - accuracy: 0.7560\n",
            "Epoch 179/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.9875 - accuracy: 0.7545\n",
            "Epoch 180/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.0087 - accuracy: 0.7480\n",
            "Epoch 181/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.9967 - accuracy: 0.7533\n",
            "Epoch 182/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.9905 - accuracy: 0.7610\n",
            "Epoch 183/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.9459 - accuracy: 0.7646\n",
            "Epoch 184/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.9611 - accuracy: 0.7603\n",
            "Epoch 185/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.9655 - accuracy: 0.7626\n",
            "Epoch 186/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.9378 - accuracy: 0.7670\n",
            "Epoch 187/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.9407 - accuracy: 0.7678\n",
            "Epoch 188/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.9794 - accuracy: 0.7560\n",
            "Epoch 189/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.9498 - accuracy: 0.7715\n",
            "Epoch 190/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.9009 - accuracy: 0.7815\n",
            "Epoch 191/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.9086 - accuracy: 0.7712\n",
            "Epoch 192/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.9138 - accuracy: 0.7736\n",
            "Epoch 193/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.1303 - accuracy: 0.7167\n",
            "Epoch 194/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 1.0451 - accuracy: 0.7411\n",
            "Epoch 195/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.9956 - accuracy: 0.7551\n",
            "Epoch 196/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.9549 - accuracy: 0.7634\n",
            "Epoch 197/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.9624 - accuracy: 0.7592\n",
            "Epoch 198/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.9251 - accuracy: 0.7703\n",
            "Epoch 199/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.9236 - accuracy: 0.7749\n",
            "Epoch 200/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8800 - accuracy: 0.7851\n",
            "Epoch 201/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8804 - accuracy: 0.7841\n",
            "Epoch 202/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8519 - accuracy: 0.7922\n",
            "Epoch 203/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8782 - accuracy: 0.7883\n",
            "Epoch 204/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8520 - accuracy: 0.7901\n",
            "Epoch 205/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8716 - accuracy: 0.7879\n",
            "Epoch 206/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.9013 - accuracy: 0.7758\n",
            "Epoch 207/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8705 - accuracy: 0.7833\n",
            "Epoch 208/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8685 - accuracy: 0.7847\n",
            "Epoch 209/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8385 - accuracy: 0.7904\n",
            "Epoch 210/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8450 - accuracy: 0.7916\n",
            "Epoch 211/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8558 - accuracy: 0.7882\n",
            "Epoch 212/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8549 - accuracy: 0.7881\n",
            "Epoch 213/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8588 - accuracy: 0.7802\n",
            "Epoch 214/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8260 - accuracy: 0.7872\n",
            "Epoch 215/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8369 - accuracy: 0.7925\n",
            "Epoch 216/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8408 - accuracy: 0.7822\n",
            "Epoch 217/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8325 - accuracy: 0.7903\n",
            "Epoch 218/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8270 - accuracy: 0.7935\n",
            "Epoch 219/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8611 - accuracy: 0.7819\n",
            "Epoch 220/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8599 - accuracy: 0.7784\n",
            "Epoch 221/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8363 - accuracy: 0.7831\n",
            "Epoch 222/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8673 - accuracy: 0.7798\n",
            "Epoch 223/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8337 - accuracy: 0.7889\n",
            "Epoch 224/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8296 - accuracy: 0.7886\n",
            "Epoch 225/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7999 - accuracy: 0.7941\n",
            "Epoch 226/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7844 - accuracy: 0.8017\n",
            "Epoch 227/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8832 - accuracy: 0.7788\n",
            "Epoch 228/500\n",
            "327/327 [==============================] - 3s 9ms/step - loss: 0.8112 - accuracy: 0.7975\n",
            "Epoch 229/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7997 - accuracy: 0.8021\n",
            "Epoch 230/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8140 - accuracy: 0.7950\n",
            "Epoch 231/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7774 - accuracy: 0.8028\n",
            "Epoch 232/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7853 - accuracy: 0.8014\n",
            "Epoch 233/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7858 - accuracy: 0.8045\n",
            "Epoch 234/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7777 - accuracy: 0.8026\n",
            "Epoch 235/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7936 - accuracy: 0.7953\n",
            "Epoch 236/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7560 - accuracy: 0.8060\n",
            "Epoch 237/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8510 - accuracy: 0.7834\n",
            "Epoch 238/500\n",
            "327/327 [==============================] - 3s 9ms/step - loss: 0.7971 - accuracy: 0.7949\n",
            "Epoch 239/500\n",
            "327/327 [==============================] - 3s 9ms/step - loss: 0.7607 - accuracy: 0.8084\n",
            "Epoch 240/500\n",
            "327/327 [==============================] - 3s 9ms/step - loss: 0.7610 - accuracy: 0.8052\n",
            "Epoch 241/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7559 - accuracy: 0.8043\n",
            "Epoch 242/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7364 - accuracy: 0.8092\n",
            "Epoch 243/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7470 - accuracy: 0.8076\n",
            "Epoch 244/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7647 - accuracy: 0.7989\n",
            "Epoch 245/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7572 - accuracy: 0.8043\n",
            "Epoch 246/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.8264 - accuracy: 0.7847\n",
            "Epoch 247/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7896 - accuracy: 0.8003\n",
            "Epoch 248/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7588 - accuracy: 0.8021\n",
            "Epoch 249/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7513 - accuracy: 0.8031\n",
            "Epoch 250/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7709 - accuracy: 0.7969\n",
            "Epoch 251/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7663 - accuracy: 0.7988\n",
            "Epoch 252/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7409 - accuracy: 0.8045\n",
            "Epoch 253/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7473 - accuracy: 0.7986\n",
            "Epoch 254/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7243 - accuracy: 0.8090\n",
            "Epoch 255/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7312 - accuracy: 0.8115\n",
            "Epoch 256/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7339 - accuracy: 0.8101\n",
            "Epoch 257/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7029 - accuracy: 0.8193\n",
            "Epoch 258/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7024 - accuracy: 0.8168\n",
            "Epoch 259/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7095 - accuracy: 0.8104\n",
            "Epoch 260/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7088 - accuracy: 0.8110\n",
            "Epoch 261/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7312 - accuracy: 0.8109\n",
            "Epoch 262/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6968 - accuracy: 0.8186\n",
            "Epoch 263/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7064 - accuracy: 0.8165\n",
            "Epoch 264/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6851 - accuracy: 0.8230\n",
            "Epoch 265/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6967 - accuracy: 0.8153\n",
            "Epoch 266/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7056 - accuracy: 0.8137\n",
            "Epoch 267/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7110 - accuracy: 0.8095\n",
            "Epoch 268/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6776 - accuracy: 0.8268\n",
            "Epoch 269/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6770 - accuracy: 0.8150\n",
            "Epoch 270/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7069 - accuracy: 0.8129\n",
            "Epoch 271/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6855 - accuracy: 0.8200\n",
            "Epoch 272/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6730 - accuracy: 0.8186\n",
            "Epoch 273/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6994 - accuracy: 0.8165\n",
            "Epoch 274/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7247 - accuracy: 0.8063\n",
            "Epoch 275/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6814 - accuracy: 0.8183\n",
            "Epoch 276/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6845 - accuracy: 0.8196\n",
            "Epoch 277/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6719 - accuracy: 0.8198\n",
            "Epoch 278/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6918 - accuracy: 0.8148\n",
            "Epoch 279/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6807 - accuracy: 0.8211\n",
            "Epoch 280/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6631 - accuracy: 0.8230\n",
            "Epoch 281/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6612 - accuracy: 0.8246\n",
            "Epoch 282/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6671 - accuracy: 0.8224\n",
            "Epoch 283/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6855 - accuracy: 0.8222\n",
            "Epoch 284/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6921 - accuracy: 0.8124\n",
            "Epoch 285/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6717 - accuracy: 0.8250\n",
            "Epoch 286/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6624 - accuracy: 0.8226\n",
            "Epoch 287/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6635 - accuracy: 0.8224\n",
            "Epoch 288/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6402 - accuracy: 0.8280\n",
            "Epoch 289/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6757 - accuracy: 0.8183\n",
            "Epoch 290/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6559 - accuracy: 0.8262\n",
            "Epoch 291/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6596 - accuracy: 0.8218\n",
            "Epoch 292/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6787 - accuracy: 0.8143\n",
            "Epoch 293/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6441 - accuracy: 0.8280\n",
            "Epoch 294/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6659 - accuracy: 0.8183\n",
            "Epoch 295/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7509 - accuracy: 0.7965\n",
            "Epoch 296/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6530 - accuracy: 0.8219\n",
            "Epoch 297/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6657 - accuracy: 0.8249\n",
            "Epoch 298/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7295 - accuracy: 0.8043\n",
            "Epoch 299/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6652 - accuracy: 0.8203\n",
            "Epoch 300/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6552 - accuracy: 0.8259\n",
            "Epoch 301/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6287 - accuracy: 0.8323\n",
            "Epoch 302/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6061 - accuracy: 0.8337\n",
            "Epoch 303/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6168 - accuracy: 0.8354\n",
            "Epoch 304/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6383 - accuracy: 0.8211\n",
            "Epoch 305/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6246 - accuracy: 0.8269\n",
            "Epoch 306/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6163 - accuracy: 0.8250\n",
            "Epoch 307/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6256 - accuracy: 0.8281\n",
            "Epoch 308/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6322 - accuracy: 0.8266\n",
            "Epoch 309/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6229 - accuracy: 0.8337\n",
            "Epoch 310/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6308 - accuracy: 0.8291\n",
            "Epoch 311/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6451 - accuracy: 0.8232\n",
            "Epoch 312/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6151 - accuracy: 0.8292\n",
            "Epoch 313/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6320 - accuracy: 0.8253\n",
            "Epoch 314/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6229 - accuracy: 0.8299\n",
            "Epoch 315/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6533 - accuracy: 0.8279\n",
            "Epoch 316/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6488 - accuracy: 0.8264\n",
            "Epoch 317/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6299 - accuracy: 0.8264\n",
            "Epoch 318/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6224 - accuracy: 0.8280\n",
            "Epoch 319/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6180 - accuracy: 0.8346\n",
            "Epoch 320/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6525 - accuracy: 0.8243\n",
            "Epoch 321/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6398 - accuracy: 0.8290\n",
            "Epoch 322/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6336 - accuracy: 0.8296\n",
            "Epoch 323/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6090 - accuracy: 0.8328\n",
            "Epoch 324/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6082 - accuracy: 0.8380\n",
            "Epoch 325/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6066 - accuracy: 0.8296\n",
            "Epoch 326/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5927 - accuracy: 0.8352\n",
            "Epoch 327/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5980 - accuracy: 0.8353\n",
            "Epoch 328/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5907 - accuracy: 0.8330\n",
            "Epoch 329/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6077 - accuracy: 0.8283\n",
            "Epoch 330/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5947 - accuracy: 0.8350\n",
            "Epoch 331/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5750 - accuracy: 0.8362\n",
            "Epoch 332/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6092 - accuracy: 0.8311\n",
            "Epoch 333/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5869 - accuracy: 0.8390\n",
            "Epoch 334/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6081 - accuracy: 0.8300\n",
            "Epoch 335/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6315 - accuracy: 0.8294\n",
            "Epoch 336/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5981 - accuracy: 0.8328\n",
            "Epoch 337/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5843 - accuracy: 0.8378\n",
            "Epoch 338/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5752 - accuracy: 0.8422\n",
            "Epoch 339/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6231 - accuracy: 0.8267\n",
            "Epoch 340/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6279 - accuracy: 0.8254\n",
            "Epoch 341/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6047 - accuracy: 0.8330\n",
            "Epoch 342/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5897 - accuracy: 0.8355\n",
            "Epoch 343/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5659 - accuracy: 0.8400\n",
            "Epoch 344/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5567 - accuracy: 0.8401\n",
            "Epoch 345/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5721 - accuracy: 0.8395\n",
            "Epoch 346/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5674 - accuracy: 0.8421\n",
            "Epoch 347/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5663 - accuracy: 0.8415\n",
            "Epoch 348/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5589 - accuracy: 0.8479\n",
            "Epoch 349/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5835 - accuracy: 0.8340\n",
            "Epoch 350/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5709 - accuracy: 0.8409\n",
            "Epoch 351/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5998 - accuracy: 0.8315\n",
            "Epoch 352/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5837 - accuracy: 0.8351\n",
            "Epoch 353/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5685 - accuracy: 0.8378\n",
            "Epoch 354/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5416 - accuracy: 0.8507\n",
            "Epoch 355/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5512 - accuracy: 0.8440\n",
            "Epoch 356/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5793 - accuracy: 0.8391\n",
            "Epoch 357/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5870 - accuracy: 0.8320\n",
            "Epoch 358/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5692 - accuracy: 0.8395\n",
            "Epoch 359/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5749 - accuracy: 0.8369\n",
            "Epoch 360/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5738 - accuracy: 0.8391\n",
            "Epoch 361/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5717 - accuracy: 0.8415\n",
            "Epoch 362/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5581 - accuracy: 0.8404\n",
            "Epoch 363/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5679 - accuracy: 0.8383\n",
            "Epoch 364/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5464 - accuracy: 0.8461\n",
            "Epoch 365/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5702 - accuracy: 0.8337\n",
            "Epoch 366/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5543 - accuracy: 0.8411\n",
            "Epoch 367/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5378 - accuracy: 0.8453\n",
            "Epoch 368/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5336 - accuracy: 0.8471\n",
            "Epoch 369/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5404 - accuracy: 0.8430\n",
            "Epoch 370/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5462 - accuracy: 0.8441\n",
            "Epoch 371/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5336 - accuracy: 0.8495\n",
            "Epoch 372/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5296 - accuracy: 0.8452\n",
            "Epoch 373/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5656 - accuracy: 0.8382\n",
            "Epoch 374/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5666 - accuracy: 0.8436\n",
            "Epoch 375/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5533 - accuracy: 0.8389\n",
            "Epoch 376/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5547 - accuracy: 0.8445\n",
            "Epoch 377/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5753 - accuracy: 0.8366\n",
            "Epoch 378/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5372 - accuracy: 0.8456\n",
            "Epoch 379/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5402 - accuracy: 0.8387\n",
            "Epoch 380/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5432 - accuracy: 0.8436\n",
            "Epoch 381/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5561 - accuracy: 0.8390\n",
            "Epoch 382/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5387 - accuracy: 0.8429\n",
            "Epoch 383/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5398 - accuracy: 0.8457\n",
            "Epoch 384/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5458 - accuracy: 0.8421\n",
            "Epoch 385/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5405 - accuracy: 0.8444\n",
            "Epoch 386/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5392 - accuracy: 0.8419\n",
            "Epoch 387/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5320 - accuracy: 0.8461\n",
            "Epoch 388/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5321 - accuracy: 0.8442\n",
            "Epoch 389/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5432 - accuracy: 0.8474\n",
            "Epoch 390/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5218 - accuracy: 0.8466\n",
            "Epoch 391/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5879 - accuracy: 0.8303\n",
            "Epoch 392/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5426 - accuracy: 0.8456\n",
            "Epoch 393/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5500 - accuracy: 0.8443\n",
            "Epoch 394/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5275 - accuracy: 0.8445\n",
            "Epoch 395/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5184 - accuracy: 0.8466\n",
            "Epoch 396/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5115 - accuracy: 0.8488\n",
            "Epoch 397/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5143 - accuracy: 0.8495\n",
            "Epoch 398/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5395 - accuracy: 0.8439\n",
            "Epoch 399/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5140 - accuracy: 0.8454\n",
            "Epoch 400/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5220 - accuracy: 0.8497\n",
            "Epoch 401/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5112 - accuracy: 0.8481\n",
            "Epoch 402/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5233 - accuracy: 0.8501\n",
            "Epoch 403/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5327 - accuracy: 0.8435\n",
            "Epoch 404/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.7286 - accuracy: 0.8049\n",
            "Epoch 405/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.6099 - accuracy: 0.8278\n",
            "Epoch 406/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5499 - accuracy: 0.8424\n",
            "Epoch 407/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5655 - accuracy: 0.8389\n",
            "Epoch 408/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5651 - accuracy: 0.8403\n",
            "Epoch 409/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5183 - accuracy: 0.8545\n",
            "Epoch 410/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5580 - accuracy: 0.8381\n",
            "Epoch 411/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5799 - accuracy: 0.8309\n",
            "Epoch 412/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5472 - accuracy: 0.8415\n",
            "Epoch 413/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5538 - accuracy: 0.8404\n",
            "Epoch 414/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5304 - accuracy: 0.8436\n",
            "Epoch 415/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5160 - accuracy: 0.8533\n",
            "Epoch 416/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5345 - accuracy: 0.8470\n",
            "Epoch 417/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5295 - accuracy: 0.8470\n",
            "Epoch 418/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5186 - accuracy: 0.8474\n",
            "Epoch 419/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5211 - accuracy: 0.8503\n",
            "Epoch 420/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5461 - accuracy: 0.8419\n",
            "Epoch 421/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5184 - accuracy: 0.8484\n",
            "Epoch 422/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5149 - accuracy: 0.8477\n",
            "Epoch 423/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5130 - accuracy: 0.8463\n",
            "Epoch 424/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5374 - accuracy: 0.8409\n",
            "Epoch 425/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5155 - accuracy: 0.8480\n",
            "Epoch 426/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5071 - accuracy: 0.8501\n",
            "Epoch 427/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5415 - accuracy: 0.8419\n",
            "Epoch 428/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5386 - accuracy: 0.8403\n",
            "Epoch 429/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5021 - accuracy: 0.8526\n",
            "Epoch 430/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5332 - accuracy: 0.8448\n",
            "Epoch 431/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5349 - accuracy: 0.8435\n",
            "Epoch 432/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5238 - accuracy: 0.8445\n",
            "Epoch 433/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4879 - accuracy: 0.8523\n",
            "Epoch 434/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5078 - accuracy: 0.8522\n",
            "Epoch 435/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4837 - accuracy: 0.8581\n",
            "Epoch 436/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5176 - accuracy: 0.8446\n",
            "Epoch 437/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5408 - accuracy: 0.8422\n",
            "Epoch 438/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5163 - accuracy: 0.8464\n",
            "Epoch 439/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5153 - accuracy: 0.8507\n",
            "Epoch 440/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4892 - accuracy: 0.8515\n",
            "Epoch 441/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4909 - accuracy: 0.8501\n",
            "Epoch 442/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5123 - accuracy: 0.8477\n",
            "Epoch 443/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5067 - accuracy: 0.8527\n",
            "Epoch 444/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5066 - accuracy: 0.8497\n",
            "Epoch 445/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5071 - accuracy: 0.8464\n",
            "Epoch 446/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5119 - accuracy: 0.8435\n",
            "Epoch 447/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4857 - accuracy: 0.8540\n",
            "Epoch 448/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5028 - accuracy: 0.8494\n",
            "Epoch 449/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4921 - accuracy: 0.8492\n",
            "Epoch 450/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4759 - accuracy: 0.8582\n",
            "Epoch 451/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4695 - accuracy: 0.8577\n",
            "Epoch 452/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4729 - accuracy: 0.8550\n",
            "Epoch 453/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5219 - accuracy: 0.8379\n",
            "Epoch 454/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4990 - accuracy: 0.8458\n",
            "Epoch 455/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5054 - accuracy: 0.8443\n",
            "Epoch 456/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5234 - accuracy: 0.8432\n",
            "Epoch 457/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4941 - accuracy: 0.8535\n",
            "Epoch 458/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4958 - accuracy: 0.8473\n",
            "Epoch 459/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4995 - accuracy: 0.8461\n",
            "Epoch 460/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4855 - accuracy: 0.8531\n",
            "Epoch 461/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4635 - accuracy: 0.8612\n",
            "Epoch 462/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5221 - accuracy: 0.8436\n",
            "Epoch 463/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4796 - accuracy: 0.8544\n",
            "Epoch 464/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5172 - accuracy: 0.8458\n",
            "Epoch 465/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5155 - accuracy: 0.8493\n",
            "Epoch 466/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4998 - accuracy: 0.8451\n",
            "Epoch 467/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4958 - accuracy: 0.8459\n",
            "Epoch 468/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4745 - accuracy: 0.8513\n",
            "Epoch 469/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4819 - accuracy: 0.8530\n",
            "Epoch 470/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5021 - accuracy: 0.8466\n",
            "Epoch 471/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4948 - accuracy: 0.8452\n",
            "Epoch 472/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5059 - accuracy: 0.8463\n",
            "Epoch 473/500\n",
            "327/327 [==============================] - 3s 9ms/step - loss: 0.4700 - accuracy: 0.8581\n",
            "Epoch 474/500\n",
            "327/327 [==============================] - 3s 9ms/step - loss: 0.5190 - accuracy: 0.8422\n",
            "Epoch 475/500\n",
            "327/327 [==============================] - 3s 9ms/step - loss: 0.5355 - accuracy: 0.8408\n",
            "Epoch 476/500\n",
            "327/327 [==============================] - 3s 9ms/step - loss: 0.5150 - accuracy: 0.8448\n",
            "Epoch 477/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4989 - accuracy: 0.8489\n",
            "Epoch 478/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5403 - accuracy: 0.8398\n",
            "Epoch 479/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4926 - accuracy: 0.8504\n",
            "Epoch 480/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4956 - accuracy: 0.8484\n",
            "Epoch 481/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5669 - accuracy: 0.8363\n",
            "Epoch 482/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5095 - accuracy: 0.8508\n",
            "Epoch 483/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5044 - accuracy: 0.8505\n",
            "Epoch 484/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4765 - accuracy: 0.8541\n",
            "Epoch 485/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5066 - accuracy: 0.8482\n",
            "Epoch 486/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4919 - accuracy: 0.8498\n",
            "Epoch 487/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4860 - accuracy: 0.8543\n",
            "Epoch 488/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4959 - accuracy: 0.8456\n",
            "Epoch 489/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5041 - accuracy: 0.8468\n",
            "Epoch 490/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4996 - accuracy: 0.8451\n",
            "Epoch 491/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4731 - accuracy: 0.8549\n",
            "Epoch 492/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4615 - accuracy: 0.8551\n",
            "Epoch 493/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4671 - accuracy: 0.8553\n",
            "Epoch 494/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4506 - accuracy: 0.8616\n",
            "Epoch 495/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4642 - accuracy: 0.8594\n",
            "Epoch 496/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4782 - accuracy: 0.8529\n",
            "Epoch 497/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4886 - accuracy: 0.8528\n",
            "Epoch 498/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.5021 - accuracy: 0.8510\n",
            "Epoch 499/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4853 - accuracy: 0.8533\n",
            "Epoch 500/500\n",
            "327/327 [==============================] - 3s 8ms/step - loss: 0.4641 - accuracy: 0.8564\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXVFpoREhV6Y"
      },
      "source": [
        "### View the Training Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeSNfS7uhch0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "f4ea3b7e-5063-48db-90ed-8a338a6dad8c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rAgRpxYhjpB"
      },
      "source": [
        "### Generate new lyrics!\n",
        "\n",
        "It's finally time to generate some new lyrics from the trained model, and see what we get. To do so, we'll provide some \"seed text\", or an input sequence for the model to start with. We'll also decide just how long of an output sequence we want - this could essentially be infinite, as the input plus the previous output will be continuously fed in for a new output word (at least up to our max sequence length).\n",
        "\n",
        "\n",
        "Por fin es hora de generar algunas letras nuevas del modelo entrenado, y ver qué obtenemos. Para ello, proporcionaremos algún \"texto de la semilla\", o una secuencia de entrada para que el modelo empiece. También decidiremos cuánto tiempo de una secuencia de salida queremos - esto podría ser esencialmente infinito, ya que la entrada más la salida anterior será continuamente alimentada por una nueva palabra de salida (al menos hasta nuestra máxima longitud de secuencia)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC7zfcgviDTp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b58ab823-7450-4997-b993-65b9220e5584"
      },
      "source": [
        "seed_text = \"She is a bad idea\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "She is a bad idea you hear you hold me what it in me that guy able about while smile and higher shopping flat mean is happened queen happened up along into me but same girl just turn while cry intention know sweet ground seem dream lies place old new where oh ship lies oh who fire eyes ground delight everythings stick just prepared think from lies crazy rustling down but fire style returning glad from returning they arms business strange sad shopping out seen habia live for believed prays chat prays memories boomerang forever flat shallow power truth volverlo help others tend so fine\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}